{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0348cc58",
   "metadata": {},
   "source": [
    "Environment: This script should be run with the `python_plant_pathogen_atlas` environment using the devcontainer `docker_python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89aee16-4a80-47ef-ba05-ba153dade15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from merfishing.core import clustering\n",
    "import diopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468faea5-7366-4f7a-a335-22decef83253",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = r'../../data'\n",
    "output_folder = r'../../outputs'\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ce2b01-5729-4e9f-b452-5b4bd1ebda2e",
   "metadata": {},
   "source": [
    "##### Let's first convert the scMultiome object with both replicates into an h5ad file so it can be loaded into python easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73e6e5-c6b7-480e-9e9f-50188868ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = diopy.input.read_h5(file = os.path.join(data_folder, 'temp_objects', 'AvrRpt2_alone2.h5'))\n",
    "seq_data.obs['modality'] = 'seq'\n",
    "seq_data.write(os.path.join(data_folder, 'temp_objects', 'seq_reference_00.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76735ee4",
   "metadata": {},
   "source": [
    "##### Here we create adata objects from the Baysor segmentation outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489fac81-ea0f-4cfc-abb6-27d0ec0b3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_baysor_segmentations = []\n",
    "for seg_name in ['mock', '4hr_avr', '6hr_avr', '9hr_avr', 'avrrpt24']:\n",
    "    list_of_baysor_segmentations.append(os.path.join(data_folder, 'segmentations', seg_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a3284-868a-4192-9f50-7dbf3cf00684",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_file in list_of_baysor_segmentations:\n",
    "    try: \n",
    "        os.mkdir(os.path.join(input_file, 'adatas'))\n",
    "    except:\n",
    "        print('Adatas dir already exists')\n",
    "    cell_stats = pd.read_csv(glob.glob(os.path.join(input_file, '*_cell_stats.csv'))[0], index_col=0)\n",
    "    cell_counts = pd.read_csv(glob.glob(os.path.join(input_file, '*_counts.tsv'))[0], sep='\\t', index_col=0)\n",
    "    adata = sc.AnnData(X=cell_counts.values.T, obs = cell_stats, var = pd.DataFrame(index = cell_counts.index.values))\n",
    "    adata.obs = cell_stats\n",
    "    adata.write(os.path.join(input_file, 'adatas', 'adata.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec989da",
   "metadata": {},
   "source": [
    "##### We save the raw counts and normalized counts into an object called preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966cb9cc-cdd4-44ab-b4f1-ff2892867c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_file in list_of_baysor_segmentations:\n",
    "    adata = sc.read(os.path.join(input_file, 'adatas', 'adata.h5ad'))\n",
    "    adata.layers['counts'] = adata.X.copy()\n",
    "    sc.pp.normalize_total(adata)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata.write(os.path.join(input_file, 'adatas', 'preprocessed_00.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbcc8ae-6e2f-44ab-a630-92ffe53eb796",
   "metadata": {},
   "source": [
    "##### Now we QC filter all objects to remove low quality cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d5e56-b0b8-457c-8ae6-3b10b0ce3358",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_file in list_of_baysor_segmentations:\n",
    "    min_transcript_threshold=50\n",
    "    max_transcript_threshold=1200\n",
    "    min_cell_area = 5\n",
    "    max_cell_area = 15000\n",
    "    min_tc_area = 0.01\n",
    "    max_tc_area = 10\n",
    "\n",
    "    #load in the current adata\n",
    "    experiment = sc.read(os.path.join(input_file, 'adatas', 'preprocessed_00.h5ad'))\n",
    "\n",
    "    print('QC metrics for batch '+os.path.basename(input_file))\n",
    "    print(f'{len(experiment.obs.index)} cells before QC filtering')\n",
    "    #remove blank barcodes\n",
    "    experiment = experiment[:, ~experiment.var.index.str.contains('Blank')]\n",
    "    experiment.obs['n_transcripts'] = np.array(experiment.layers['counts'].sum(axis=1))\n",
    "\n",
    "    #remove cells that fall outside of area constraints\n",
    "    experiment = experiment[(experiment.obs['area'] > min_cell_area) & (experiment.obs['area'] < max_cell_area), :]\n",
    "\n",
    "\n",
    "    experiment = experiment[(experiment.obs['n_transcripts'] > min_transcript_threshold) & (experiment.obs['n_transcripts'] < max_transcript_threshold), :]\n",
    "\n",
    "    experiment.obs['transcript_counts_div_cell_area'] = experiment.obs['n_transcripts']/experiment.obs['area']\n",
    "\n",
    "    experiment = experiment[experiment.obs['transcript_counts_div_cell_area'] < np.percentile(experiment.obs['transcript_counts_div_cell_area'], 99.5)]\n",
    "    \n",
    "    experiment = experiment[(experiment.obs['transcript_counts_div_cell_area'] > min_tc_area) & (experiment.obs['transcript_counts_div_cell_area'] < max_tc_area), :]\n",
    "    print(f'{len(experiment.obs.index)} cells after QC filtering')\n",
    "    \n",
    "    df = pd.DataFrame(experiment.X, columns=experiment.var.index.values, index=experiment.obs.index.values)\n",
    "    metadata = experiment.obs\n",
    "    \n",
    "    sc.pl.violin(experiment, keys=['n_transcripts', 'area', 'transcript_counts_div_cell_area'])\n",
    "    \n",
    "    experiment.write(os.path.join(input_file, 'adatas', 'preprocessed_and_filtered_01.h5ad'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
