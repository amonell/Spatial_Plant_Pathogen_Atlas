{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Environment: This script should be run with the `python_plant_pathogen_atlas` environment using the devcontainer `docker_python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from merfishing.core import clustering\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import diopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = r\"../../data\"\n",
    "output_folder = r\"../../outputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "In the following cell, we convert our DC3000 multiome object into an anndata object. This will allow us to use the scanpy package to perform the clustering and visualization of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = diopy.input.read_h5(\n",
    "    file=os.path.join(data_folder, \"temp_objects\", \"DC3000_alone.h5\")\n",
    ")\n",
    "seq_data.obs[\"modality\"] = \"seq\"\n",
    "seq_data.write(os.path.join(data_folder, \"temp_objects\", \"DC3000_alone.h5ad\"))\n",
    "\n",
    "try:\n",
    "    os.remove(os.path.join(data_folder, \"temp_objects\", \"DC3000_alone.h5\"))\n",
    "except:\n",
    "    print(\"DC3000_alone.h5 already removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "We can now put in the path to our DC3000 Baysor segmentation folder to read in the MERFISH data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_baysor_segmentations = [os.path.join(data_folder, \"segmentations\", \"kt56\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_file in list_of_baysor_segmentations:\n",
    "    try:\n",
    "        os.mkdir(os.path.join(input_file, \"adatas\"))\n",
    "    except:\n",
    "        print(\"Adatas dir already exists\")\n",
    "    cell_stats = pd.read_csv(\n",
    "        glob.glob(os.path.join(input_file, \"*_cell_stats.csv\"))[0], index_col=0\n",
    "    )\n",
    "    cell_counts = pd.read_csv(\n",
    "        glob.glob(os.path.join(input_file, \"*_counts.tsv\"))[0], sep=\"\\t\", index_col=0\n",
    "    )\n",
    "    adata = sc.AnnData(\n",
    "        X=cell_counts.values.T,\n",
    "        obs=cell_stats,\n",
    "        var=pd.DataFrame(index=cell_counts.index.values),\n",
    "    )\n",
    "    adata.obs = cell_stats\n",
    "    adata.write(os.path.join(input_file, \"adatas\", \"adata.h5ad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Let's store the raw counts in an adata layer, and perform log normalization. It is often advised to use raw counts when processing spatial data, so we want to hold onto them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_file in list_of_baysor_segmentations:\n",
    "    adata = sc.read(os.path.join(input_file, \"adatas\", \"adata.h5ad\"))\n",
    "    adata.layers[\"counts\"] = adata.X.copy()\n",
    "    sc.pp.normalize_total(adata)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata.write(os.path.join(input_file, \"adatas\", \"preprocessed_00.h5ad\"))\n",
    "\n",
    "    try:\n",
    "        os.remove(os.path.join(input_file, \"adatas\", \"adata.h5ad\"))\n",
    "    except:\n",
    "        print(\"Could not remove original adata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "The following cell performs QC filtering on the DC3000 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_file in list_of_baysor_segmentations:\n",
    "    min_transcript_threshold = 50\n",
    "    max_transcript_threshold = 1200\n",
    "    min_cell_area = 5\n",
    "    max_cell_area = 15000\n",
    "    min_tc_area = 0.01\n",
    "    max_tc_area = 10\n",
    "\n",
    "    experiment = sc.read(os.path.join(input_file, \"adatas\", \"preprocessed_00.h5ad\"))\n",
    "    print(experiment)\n",
    "    experiment = experiment[\n",
    "        (experiment.obs[\"area\"] > min_cell_area)\n",
    "        & (experiment.obs[\"area\"] < max_cell_area),\n",
    "        :,\n",
    "    ]\n",
    "    experiment = experiment[\n",
    "        (experiment.obs[\"n_transcripts\"] > min_transcript_threshold)\n",
    "        & (experiment.obs[\"n_transcripts\"] < max_transcript_threshold),\n",
    "        :,\n",
    "    ]\n",
    "    experiment.obs[\"transcript_counts_div_cell_area\"] = (\n",
    "        experiment.obs[\"n_transcripts\"] / experiment.obs[\"area\"]\n",
    "    )\n",
    "\n",
    "    print(\"QC metrics for batch \" + os.path.basename(input_file))\n",
    "    print(f\"{len(experiment.obs.index)} cells before QC filtering\")\n",
    "\n",
    "    experiment = experiment[\n",
    "        experiment.obs[\"transcript_counts_div_cell_area\"]\n",
    "        < np.percentile(experiment.obs[\"transcript_counts_div_cell_area\"], 99.5)\n",
    "    ]\n",
    "\n",
    "    experiment = experiment[\n",
    "        (experiment.obs[\"transcript_counts_div_cell_area\"] > min_tc_area)\n",
    "        & (experiment.obs[\"transcript_counts_div_cell_area\"] < max_tc_area),\n",
    "        :,\n",
    "    ]\n",
    "    print(f\"{len(experiment.obs.index)} cells after QC filtering\")\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        experiment.X,\n",
    "        columns=experiment.var.index.values,\n",
    "        index=experiment.obs.index.values,\n",
    "    )\n",
    "    metadata = experiment.obs\n",
    "\n",
    "    experiment.write(\n",
    "        os.path.join(input_file, \"adatas\", \"preprocessed_and_filtered_01.h5ad\")\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        os.remove(os.path.join(input_file, \"adatas\", \"preprocessed_00.h5ad\"))\n",
    "    except:\n",
    "        print(\"Could not remove preprocessed_00.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The following cell will convert gene IDs to gene symbols in the preprocessed and filtered object. It also removes blank barcodes from the cellxgene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = list_of_baysor_segmentations[0]\n",
    "\n",
    "spatial_data = sc.read(\n",
    "    os.path.join(input_file, \"adatas\", \"preprocessed_and_filtered_01.h5ad\")\n",
    ")\n",
    "spatial_data.obs[\"batch\"] = os.path.basename(input_file)\n",
    "\n",
    "spatial_data = spatial_data[:, ~spatial_data.var.index.str.contains(\"Blank\")]\n",
    "spatial_data.obs_names_make_unique()\n",
    "spatial_data.var_names_make_unique()\n",
    "\n",
    "gene_symbols = pd.read_csv(\n",
    "    os.path.join(data_folder, \"useful_files\", \"geneID_to_geneName_MERSCOPE_panel1.txt\"),\n",
    "    sep=\"\\t\",\n",
    "    index_col=0,\n",
    ")\n",
    "new_indices = spatial_data.var.merge(\n",
    "    gene_symbols, left_index=True, right_on=\"gene_id\"\n",
    ").index.tolist()\n",
    "gene_names = spatial_data.var.merge(\n",
    "    gene_symbols, left_index=True, right_on=\"gene_id\"\n",
    ").gene_name.tolist()\n",
    "gene_id = spatial_data.var.merge(\n",
    "    gene_symbols, left_index=True, right_on=\"gene_id\"\n",
    ").gene_id.tolist()\n",
    "spatial_data = spatial_data[:, gene_id]\n",
    "new_vars = spatial_data.var.merge(gene_symbols, left_index=True, right_on=\"gene_id\")\n",
    "new_vars.index = new_vars.gene_name.tolist()\n",
    "new_vars = new_vars.drop([\"gene_name\"], axis=1)\n",
    "spatial_data.var = new_vars\n",
    "\n",
    "spatial_data.write(\n",
    "    os.path.join(input_file, \"adatas\", \"preprocessed_and_filtered_02.h5ad\")\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    os.remove(os.path.join(input_file, \"adatas\", \"preprocessed_and_filtered_01.h5ad\"))\n",
    "except:\n",
    "    print(\"Could not remove preprocessed_and_filtered_01.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
